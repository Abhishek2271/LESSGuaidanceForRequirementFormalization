{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Test IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g. 'Variables', 'Components', 'Objects')\n",
    "    from the specification document.\n",
    "    \n",
    "    Parameters:\n",
    "        spec_text (str): Full text of the specification document.\n",
    "        key (str): The key to search for (e.g., \"Variables\").\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tokens extracted from the list.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        # Split by comma and remove extra whitespace/newlines.\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\" take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    \n",
    "    It uses a regex to capture the requirement ID and the text inside the curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects.\n",
    "    \n",
    "    Testobjects are determined by matching tokens in the requirement text with the union\n",
    "    of tokens found in the Variables, Components, and Objects lists from the spec.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the lists in the spec\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    print(components)\n",
    "    objects = extract_list(spec_text, \"Objects\")  # if no Objects section, this will be empty\n",
    "    token_set = set(variables + components + objects)\n",
    "    #print(token_set)\n",
    "    # Extract requirement blocks\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            # Check if the token appears as a whole word in the block_text\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens)\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart_test_with_grammar.ess\"  # Name of the specification document file\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    # Print the output as formatted JSON\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate TestCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        # Split by comma and remove extra whitespace/newlines.\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre(block_text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the entire requirement block text.\n",
    "    \n",
    "    This function searches for patterns where (optionally) a component/variable is\n",
    "    followed by one of the antecedent keywords (IN CASE OF, FROM, WHILE, DURING, or IN \n",
    "    when not followed by AS SOON AS, TO, or BEFORE) and then a state.\n",
    "    \n",
    "    If a negation (e.g., \"NOT\") is detected, the corresponding state value is set to False.\n",
    "    \n",
    "    If the captured component is not in token_set or is missing, the condition key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with keys either \"component:state\" (if component is valid) or just \"state\",\n",
    "              and boolean values.\n",
    "    \"\"\"\n",
    "    pre_conditions = {}\n",
    "    pattern = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?:(?P<component>\\S+)\\s+)?(?P<keyword>(?:IN CASE OF|FROM|WHILE|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE))))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, block_text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        # If there is no valid component (or it's not in token_set), use the state as key.\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        pre_conditions[key] = not negation\n",
    "    return pre_conditions\n",
    "\n",
    "def extract_post(block_text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the entire requirement block text.\n",
    "    \n",
    "    It searches for patterns where (optionally) a component/variable/object directly precedes \n",
    "    the keyword \"TO\" and then is followed by a state (optionally with \"STATE\").\n",
    "    \n",
    "    If the captured component is not in token_set or is missing, the key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with keys either \"component:state\" (if component is valid) or just \"state\",\n",
    "              and a boolean value True.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, block_text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        post_conditions[key] = True\n",
    "    return post_conditions\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    Testobjects are determined by matching tokens in the requirement text with the union\n",
    "    of tokens found in the Variables, Components, and Objects lists from the spec.\n",
    "    \n",
    "    PRE conditions are built by scanning the entire requirement block for antecedent conditions,\n",
    "    while POST conditions are built by scanning for patterns where a component/variable/object is\n",
    "    directly preceding \"TO\" and then a state.\n",
    "    \n",
    "    Only tokens present in the defined token set are used as components; otherwise, the condition\n",
    "    key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the lists in the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")  # if no Objects section, this will be empty\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        pre_conditions = extract_pre(block_text, token_set)\n",
    "        post_conditions = extract_post(block_text, token_set)\n",
    "        \n",
    "        # Extract Testobjects by checking for tokens present anywhere in the block text.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_conditions,\n",
    "            \"POST\": post_conditions\n",
    "            # Action can be added similarly if needed.\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart_test_with_grammar.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    # Print the output as formatted JSON.\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALSO HANDLE SHALL NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre_conditions(text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the given text.\n",
    "    \n",
    "    Searches for patterns using antecedent keywords other than \"TO\" (e.g. FROM, WHILE, IN CASE OF, DURING, \n",
    "    and IN if not followed by AS SOON AS, TO, or BEFORE).\n",
    "    \n",
    "    If a component is captured and is in token_set, the key becomes \"component:state\";\n",
    "    otherwise, the key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are either \"component:state\" or just \"state\" with boolean values.\n",
    "    \"\"\"\n",
    "    pre_conditions = {}\n",
    "    pattern = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?:(?P<component>\\S+)\\s+)?(?P<keyword>(?:FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE))))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        pre_conditions[key] = not negation\n",
    "    return pre_conditions\n",
    "\n",
    "def extract_post_conditions(text, token_set, default_value):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the given text by scanning for \"TO\" clauses.\n",
    "    \n",
    "    The pattern optionally captures a component immediately preceding \"TO\". If a valid component is captured\n",
    "    (i.e. it exists in token_set), the key becomes \"component:state\"; otherwise, the key is just \"state\".\n",
    "    \n",
    "    The boolean value for each occurrence is set to default_value.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is not None and component in token_set:\n",
    "            key = f\"{component}:{state}\"\n",
    "        else:\n",
    "            key = state\n",
    "        post_conditions[key] = default_value\n",
    "    return post_conditions\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    The requirement block is split into two parts based on the first occurrence of \"SHALL\" or \"SHALL NOT\":\n",
    "      - condition_part: everything before the split keyword\n",
    "      - action_part: everything after the split keyword\n",
    "    \n",
    "    The splitting keyword (captured from the regex) determines the default value for the action part:\n",
    "      - \"SHALL\" implies a default of True.\n",
    "      - \"SHALL NOT\" implies a default of False.\n",
    "    \n",
    "    From the condition_part:\n",
    "      - PRE conditions are extracted using antecedent keywords (excluding \"TO\").\n",
    "      - \"TO\" clauses are also extracted as POST conditions with a default True value.\n",
    "    \n",
    "    From the action_part:\n",
    "      - \"TO\" clauses are extracted as POST conditions with the default determined by the splitting keyword.\n",
    "    \n",
    "    Testobjects are determined by matching tokens from Variables, Components, and Objects anywhere in the block.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    # Split using \"SHALL\" or \"SHALL NOT\" (capturing which one is used).\n",
    "    split_re = r\"\\b(SHALL(?:\\s+NOT)?)\\b\"\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        parts = re.split(split_re, block_text, maxsplit=1, flags=re.IGNORECASE)\n",
    "        if len(parts) == 3:\n",
    "            condition_part = parts[0]\n",
    "            splitting_keyword = parts[1]\n",
    "            action_part = parts[2]\n",
    "        else:\n",
    "            condition_part = block_text\n",
    "            splitting_keyword = \"SHALL\"  # default if not found\n",
    "            action_part = \"\"\n",
    "        \n",
    "        # Determine default value for the action part based on the splitting keyword.\n",
    "        action_default = False if \"NOT\" in splitting_keyword.upper() else True\n",
    "        \n",
    "        # Extract PRE from condition part (using antecedent keywords excluding \"TO\").\n",
    "        pre_conditions = extract_pre_conditions(condition_part, token_set)\n",
    "        \n",
    "        # Extract POST conditions:\n",
    "        # From condition part: any \"TO\" clauses get default True.\n",
    "        post_conditions_condition = extract_post_conditions(condition_part, token_set, True)\n",
    "        # From action part: default as determined by the splitting keyword.\n",
    "        post_conditions_action = extract_post_conditions(action_part, token_set, action_default)\n",
    "        \n",
    "        # Combine POST conditions; if the same key appears, action part takes precedence.\n",
    "        post_conditions = {**post_conditions_condition, **post_conditions_action}\n",
    "        \n",
    "        # Determine Testobjects by scanning the entire block for tokens in token_set.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_conditions,\n",
    "            \"POST\": post_conditions\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart_test_with_grammar.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NON-JSON FORMATTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre_conditions(text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the given text.\n",
    "    \n",
    "    Searches for patterns using antecedent keywords other than \"TO\" (e.g. FROM, WHILE, IN CASE OF, DURING, \n",
    "    and IN if not followed by AS SOON AS, TO, or BEFORE).\n",
    "    \n",
    "    If a component is captured and is in token_set, the key becomes \"component:state\";\n",
    "    otherwise, the key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are either \"component:state\" or just \"state\" with boolean values.\n",
    "    \"\"\"\n",
    "    pre_conditions = {}\n",
    "    pattern = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?:(?P<component>\\S+)\\s+)?(?P<keyword>(?:FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE))))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        pre_conditions[key] = not negation\n",
    "    return pre_conditions\n",
    "\n",
    "def extract_post_conditions(text, token_set, default_value):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the given text by scanning for \"TO\" clauses.\n",
    "    \n",
    "    The pattern optionally captures a component immediately preceding \"TO\". If a valid component is captured\n",
    "    (i.e. it exists in token_set), the key becomes \"component:state\"; otherwise, the key is just \"state\".\n",
    "    \n",
    "    The boolean value for each occurrence is set to default_value.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is not None and component in token_set:\n",
    "            key = f\"{component}:{state}\"\n",
    "        else:\n",
    "            key = state\n",
    "        post_conditions[key] = default_value\n",
    "    return post_conditions\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    The requirement block is split into two parts based on the first occurrence of \"SHALL\" or \"SHALL NOT\":\n",
    "      - condition_part: everything before the split keyword\n",
    "      - action_part: everything after the split keyword\n",
    "    \n",
    "    The splitting keyword (captured from the regex) determines the default value for the action part:\n",
    "      - \"SHALL\" implies a default of True.\n",
    "      - \"SHALL NOT\" implies a default of False.\n",
    "    \n",
    "    From the condition_part:\n",
    "      - PRE conditions are extracted using antecedent keywords (excluding \"TO\").\n",
    "      - \"TO\" clauses are also extracted as POST conditions with a default True value.\n",
    "    \n",
    "    From the action_part:\n",
    "      - \"TO\" clauses are extracted as POST conditions with the default determined by the splitting keyword.\n",
    "    \n",
    "    Testobjects are determined by matching tokens from Variables, Components, and Objects anywhere in the block.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    # Split using \"SHALL\" or \"SHALL NOT\" (capturing which one is used).\n",
    "    split_re = r\"\\b(SHALL(?:\\s+NOT)?)\\b\"\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        parts = re.split(split_re, block_text, maxsplit=1, flags=re.IGNORECASE)\n",
    "        if len(parts) == 3:\n",
    "            condition_part = parts[0]\n",
    "            splitting_keyword = parts[1]\n",
    "            action_part = parts[2]\n",
    "        else:\n",
    "            condition_part = block_text\n",
    "            splitting_keyword = \"SHALL\"  # default if not found\n",
    "            action_part = \"\"\n",
    "        \n",
    "        # Determine default value for the action part based on the splitting keyword.\n",
    "        action_default = False if \"NOT\" in splitting_keyword.upper() else True\n",
    "        \n",
    "        # Extract PRE from condition part (using antecedent keywords excluding \"TO\").\n",
    "        pre_conditions = extract_pre_conditions(condition_part, token_set)\n",
    "        \n",
    "        # Extract POST conditions:\n",
    "        # From condition part: any \"TO\" clauses get default True.\n",
    "        post_conditions_condition = extract_post_conditions(condition_part, token_set, True)\n",
    "        # From action part: default as determined by the splitting keyword.\n",
    "        post_conditions_action = extract_post_conditions(action_part, token_set, action_default)\n",
    "        \n",
    "        # Combine POST conditions; if the same key appears, action part takes precedence.\n",
    "        post_conditions = {**post_conditions_condition, **post_conditions_action}\n",
    "        \n",
    "        # Determine Testobjects by scanning the entire block for tokens in token_set.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_conditions,\n",
    "            \"POST\": post_conditions\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "# Custom formatting functions for printing without quotes\n",
    "def custom_format(obj):\n",
    "    \"\"\"Recursively formats lists and dictionaries without quotes for keys and string values.\"\"\"\n",
    "    if isinstance(obj, bool):\n",
    "        return \"true\" if obj else \"false\"\n",
    "    elif isinstance(obj, str):\n",
    "        return obj\n",
    "    elif isinstance(obj, list):\n",
    "        return \"[\" + \", \".join(custom_format(item) for item in obj) + \"]\"\n",
    "    elif isinstance(obj, dict):\n",
    "        items = []\n",
    "        for k, v in obj.items():\n",
    "            items.append(f\"{k}: {custom_format(v)}\")\n",
    "        return \"{\" + \", \".join(items) + \"}\"\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "def print_test_case(test_case):\n",
    "    \"\"\"Prints a test case in the desired format without quotes.\"\"\"\n",
    "    print(\"Reference:\", custom_format(test_case[\"Reference\"]))\n",
    "    print(\"Requirement:\", custom_format(test_case[\"Requirement\"]))\n",
    "    print(\"Testobjects:\", custom_format(test_case[\"Testobjects\"]))\n",
    "    print(\"PRE:\", custom_format(test_case[\"PRE\"]))\n",
    "    print(\"POST:\", custom_format(test_case[\"POST\"]))\n",
    "    print(\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart_test_with_grammar.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    \n",
    "    # Print each test case in the desired custom format.\n",
    "    for tc in test_cases:\n",
    "        print_test_case(tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON FORMATTED WITH STATES AND COMPONENTS SEPARATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre_conditions(text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the given text.\n",
    "    \n",
    "    Searches for patterns using antecedent keywords other than \"TO\" (e.g. FROM, WHILE, IN CASE OF, DURING, \n",
    "    and IN if not followed by AS SOON AS, TO, or BEFORE).\n",
    "    \n",
    "    If a component is captured and is in token_set, the key becomes \"component:state\";\n",
    "    otherwise, the key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are either \"component:state\" or just \"state\" with boolean values.\n",
    "    \"\"\"\n",
    "    pre_conditions = {}\n",
    "    pattern = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?:(?P<component>\\S+)\\s+)?(?P<keyword>(?:FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE))))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        pre_conditions[key] = not negation\n",
    "    return pre_conditions\n",
    "\n",
    "def extract_post_conditions(text, token_set, default_value):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the given text by scanning for \"TO\" clauses.\n",
    "    \n",
    "    The pattern optionally captures a component immediately preceding \"TO\". If a valid component is captured\n",
    "    (i.e. it exists in token_set), the key becomes \"component:state\"; otherwise, the key is just \"state\".\n",
    "    \n",
    "    The boolean value for each occurrence is set to default_value.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is not None and component in token_set:\n",
    "            key = f\"{component}:{state}\"\n",
    "        else:\n",
    "            key = state\n",
    "        post_conditions[key] = default_value\n",
    "    return post_conditions\n",
    "\n",
    "def transform_conditions(flat_conditions):\n",
    "    \"\"\"\n",
    "    Transforms a flat dictionary of conditions with keys like \"component:state\" \n",
    "    into a nested dictionary where the outer keys are component names and the inner keys are states.\n",
    "    \n",
    "    For example, {\"compact_drive:failed\": true, \"clinical_ui:is_running\": true} becomes:\n",
    "      {\n",
    "        \"compact_drive\": { \"failed\": true },\n",
    "        \"clinical_ui\": { \"is_running\": true }\n",
    "      }\n",
    "    \"\"\"\n",
    "    nested = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "            if comp in nested:\n",
    "                nested[comp][state] = value\n",
    "            else:\n",
    "                nested[comp] = { state: value }\n",
    "        else:\n",
    "            # If no colon is found, we keep it at top level.\n",
    "            nested[key] = value\n",
    "    return nested\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    The requirement block is split into two parts based on the first occurrence of \"SHALL\" or \"SHALL NOT\":\n",
    "      - condition_part: everything before the split keyword\n",
    "      - action_part: everything after the split keyword\n",
    "    \n",
    "    The splitting keyword (captured from the regex) determines the default value for the action part:\n",
    "      - \"SHALL\" implies a default of True.\n",
    "      - \"SHALL NOT\" implies a default of False.\n",
    "    \n",
    "    From the condition_part:\n",
    "      - PRE conditions are extracted using antecedent keywords (excluding \"TO\").\n",
    "      - \"TO\" clauses are also extracted as POST conditions with a default True value.\n",
    "    \n",
    "    From the action_part:\n",
    "      - \"TO\" clauses are extracted as POST conditions with the default determined by the splitting keyword.\n",
    "    \n",
    "    Testobjects are determined by matching tokens from Variables, Components, and Objects anywhere in the block.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    # Split using \"SHALL\" or \"SHALL NOT\" (capturing which one is used).\n",
    "    split_re = r\"\\b(SHALL(?:\\s+NOT)?)\\b\"\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        parts = re.split(split_re, block_text, maxsplit=1, flags=re.IGNORECASE)\n",
    "        if len(parts) == 3:\n",
    "            condition_part = parts[0]\n",
    "            splitting_keyword = parts[1]\n",
    "            action_part = parts[2]\n",
    "        else:\n",
    "            condition_part = block_text\n",
    "            splitting_keyword = \"SHALL\"  # default if not found\n",
    "            action_part = \"\"\n",
    "        \n",
    "        # Determine default value for the action part based on the splitting keyword.\n",
    "        action_default = False if \"NOT\" in splitting_keyword.upper() else True\n",
    "        \n",
    "        # Extract PRE from condition part (using antecedent keywords excluding \"TO\").\n",
    "        pre_conditions = extract_pre_conditions(condition_part, token_set)\n",
    "        \n",
    "        # Extract POST conditions:\n",
    "        # From condition part: any \"TO\" clauses get default True.\n",
    "        post_conditions_condition = extract_post_conditions(condition_part, token_set, True)\n",
    "        # From action part: default as determined by the splitting keyword.\n",
    "        post_conditions_action = extract_post_conditions(action_part, token_set, action_default)\n",
    "        \n",
    "        # Combine POST conditions; if the same key appears, action part takes precedence.\n",
    "        post_conditions = {**post_conditions_condition, **post_conditions_action}\n",
    "        \n",
    "        # Determine Testobjects by scanning the entire block for tokens in token_set.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        # Transform the flat condition dictionaries to nested ones.\n",
    "        pre_nested = transform_conditions(pre_conditions)\n",
    "        post_nested = transform_conditions(post_conditions)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_nested,\n",
    "            \"POST\": post_nested\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart_test_with_grammar.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only show  states which are on States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects', 'States')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre_conditions(text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the given text.\n",
    "    \n",
    "    Searches for patterns using antecedent keywords other than \"TO\" (e.g. FROM, WHILE, IN CASE OF, DURING, \n",
    "    and IN if not followed by AS SOON AS, TO, or BEFORE).\n",
    "    \n",
    "    If a component is captured and is in token_set, the key becomes \"component:state\";\n",
    "    otherwise, the key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are either \"component:state\" or just \"state\" with boolean values.\n",
    "    \"\"\"\n",
    "    pre_conditions = {}\n",
    "    pattern = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?:(?P<component>\\S+)\\s+)?(?P<keyword>(?:FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE))))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        pre_conditions[key] = not negation\n",
    "    return pre_conditions\n",
    "\n",
    "def extract_post_conditions(text, token_set, default_value):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the given text by scanning for \"TO\" clauses.\n",
    "    \n",
    "    The pattern optionally captures a component immediately preceding \"TO\". If a valid component is captured\n",
    "    (i.e. it exists in token_set), the key becomes \"component:state\"; otherwise, the key is just \"state\".\n",
    "    \n",
    "    The boolean value for each occurrence is set to default_value.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is not None and component in token_set:\n",
    "            key = f\"{component}:{state}\"\n",
    "        else:\n",
    "            key = state\n",
    "        post_conditions[key] = default_value\n",
    "    return post_conditions\n",
    "\n",
    "def transform_conditions(flat_conditions):\n",
    "    \"\"\"\n",
    "    Transforms a flat dictionary of conditions with keys like \"component:state\" \n",
    "    into a nested dictionary where the outer keys are component names and the inner keys are states.\n",
    "    \n",
    "    For example, {\"compact_drive:failed\": true, \"clinical_ui:is_running\": true} becomes:\n",
    "      {\n",
    "        \"compact_drive\": { \"failed\": true },\n",
    "        \"clinical_ui\": { \"is_running\": true }\n",
    "      }\n",
    "    \"\"\"\n",
    "    nested = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "            if comp in nested:\n",
    "                nested[comp][state] = value\n",
    "            else:\n",
    "                nested[comp] = { state: value }\n",
    "        else:\n",
    "            # No component, so keep it as a key with its value.\n",
    "            nested[key] = value\n",
    "    return nested\n",
    "\n",
    "def filter_conditions_by_states(flat_conditions, valid_states):\n",
    "    \"\"\"\n",
    "    Filters out any condition from the flat dictionary if its state is not in the valid_states set.\n",
    "    \n",
    "    For keys in the format \"component:state\", state is the substring after the colon.\n",
    "    For keys without a colon, the key itself is the state.\n",
    "    \"\"\"\n",
    "    filtered = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "        else:\n",
    "            state = key\n",
    "        if state in valid_states:\n",
    "            filtered[key] = value\n",
    "    return filtered\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    The requirement block is split into two parts based on the first occurrence of \"SHALL\" or \"SHALL NOT\":\n",
    "      - condition_part: everything before the split keyword\n",
    "      - action_part: everything after the split keyword\n",
    "    \n",
    "    The splitting keyword (captured from the regex) determines the default value for the action part:\n",
    "      - \"SHALL\" implies a default of True.\n",
    "      - \"SHALL NOT\" implies a default of False.\n",
    "    \n",
    "    From the condition_part:\n",
    "      - PRE conditions are extracted using antecedent keywords (excluding \"TO\").\n",
    "      - \"TO\" clauses are also extracted as POST conditions with a default True value.\n",
    "    \n",
    "    From the action_part:\n",
    "      - \"TO\" clauses are extracted as POST conditions with the default determined by the splitting keyword.\n",
    "    \n",
    "    Testobjects are determined by matching tokens from Variables, Components, and Objects anywhere in the block.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract valid states from the specification.\n",
    "    valid_states = set(extract_list(spec_text, \"States\"))\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    # Split using \"SHALL\" or \"SHALL NOT\" (capturing which one is used).\n",
    "    split_re = r\"\\b(SHALL(?:\\s+NOT)?)\\b\"\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        parts = re.split(split_re, block_text, maxsplit=1, flags=re.IGNORECASE)\n",
    "        if len(parts) == 3:\n",
    "            condition_part = parts[0]\n",
    "            splitting_keyword = parts[1]\n",
    "            action_part = parts[2]\n",
    "        else:\n",
    "            condition_part = block_text\n",
    "            splitting_keyword = \"SHALL\"  # default if not found\n",
    "            action_part = \"\"\n",
    "        \n",
    "        # Determine default value for the action part based on the splitting keyword.\n",
    "        action_default = False if \"NOT\" in splitting_keyword.upper() else True\n",
    "        \n",
    "        # Extract PRE from condition part (using antecedent keywords excluding \"TO\").\n",
    "        pre_conditions = extract_pre_conditions(condition_part, token_set)\n",
    "        # Extract POST conditions:\n",
    "        # From condition part: any \"TO\" clauses get default True.\n",
    "        post_conditions_condition = extract_post_conditions(condition_part, token_set, True)\n",
    "        # From action part: default as determined by the splitting keyword.\n",
    "        post_conditions_action = extract_post_conditions(action_part, token_set, action_default)\n",
    "        \n",
    "        # Combine POST conditions; if the same key appears, action part takes precedence.\n",
    "        post_conditions = {**post_conditions_condition, **post_conditions_action}\n",
    "        \n",
    "        # Filter conditions to only include states present in valid_states.\n",
    "        pre_conditions = filter_conditions_by_states(pre_conditions, valid_states)\n",
    "        post_conditions = filter_conditions_by_states(post_conditions, valid_states)\n",
    "        \n",
    "        # Determine Testobjects by scanning the entire block for tokens in token_set.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        # Transform the flat condition dictionaries to nested ones.\n",
    "        pre_nested = transform_conditions(pre_conditions)\n",
    "        post_nested = transform_conditions(post_conditions)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_nested,\n",
    "            \"POST\": post_nested\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FROM TO should have source true destination falase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects', 'States')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre_conditions(text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the given text.\n",
    "    \n",
    "    Searches for patterns using antecedent keywords other than \"TO\" (e.g. FROM, WHILE, IN CASE OF, DURING, \n",
    "    and IN if not followed by AS SOON AS, TO, or BEFORE).\n",
    "    \n",
    "    If a component is captured and is in token_set, the key becomes \"component:state\";\n",
    "    otherwise, the key is just the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Keys are either \"component:state\" or just \"state\" with boolean values.\n",
    "    \"\"\"\n",
    "    pre_conditions = {}\n",
    "    pattern = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?:(?P<component>\\S+)\\s+)?(?P<keyword>(?:FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE))))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        if component is None or component not in token_set:\n",
    "            key = state\n",
    "        else:\n",
    "            key = f\"{component}:{state}\"\n",
    "        pre_conditions[key] = not negation\n",
    "    return pre_conditions\n",
    "\n",
    "def extract_post_conditions(text, token_set, default_value):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the given text by scanning for \"TO\" clauses.\n",
    "    \n",
    "    The pattern optionally captures a component immediately preceding \"TO\". If a valid component is captured\n",
    "    (i.e. it exists in token_set), the key becomes \"component:state\"; otherwise, the key is just \"state\".\n",
    "    \n",
    "    The boolean value for each occurrence is set to default_value.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is not None and component in token_set:\n",
    "            key = f\"{component}:{state}\"\n",
    "        else:\n",
    "            key = state\n",
    "        post_conditions[key] = default_value\n",
    "    return post_conditions\n",
    "\n",
    "def transform_conditions(flat_conditions):\n",
    "    \"\"\"\n",
    "    Transforms a flat dictionary of conditions with keys like \"component:state\" \n",
    "    into a nested dictionary where the outer keys are component names and the inner keys are states.\n",
    "    \n",
    "    For example, {\"compact_drive:failed\": true, \"clinical_ui:is_running\": true} becomes:\n",
    "      {\n",
    "        \"compact_drive\": { \"failed\": true },\n",
    "        \"clinical_ui\": { \"is_running\": true }\n",
    "      }\n",
    "    \"\"\"\n",
    "    nested = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "            if comp in nested:\n",
    "                nested[comp][state] = value\n",
    "            else:\n",
    "                nested[comp] = { state: value }\n",
    "        else:\n",
    "            # No component, so keep it as a key with its value.\n",
    "            nested[key] = value\n",
    "    return nested\n",
    "\n",
    "def filter_conditions_by_states(flat_conditions, valid_states):\n",
    "    \"\"\"\n",
    "    Filters out any condition from the flat dictionary if its state is not in the valid_states set.\n",
    "    \n",
    "    For keys in the format \"component:state\", state is the substring after the colon.\n",
    "    For keys without a colon, the key itself is the state.\n",
    "    \"\"\"\n",
    "    filtered = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "        else:\n",
    "            state = key\n",
    "        if state in valid_states:\n",
    "            filtered[key] = value\n",
    "    return filtered\n",
    "\n",
    "def extract_transition_conditions(text, valid_states):\n",
    "    \"\"\"\n",
    "    Extracts state transition conditions from text for patterns like:\n",
    "      FROM state_src TO state_target\n",
    "      \n",
    "    Returns two flat dictionaries:\n",
    "      - transition_pre: { state_src: True, state_target: False }\n",
    "      - transition_post: { state_src: False, state_target: True }\n",
    "    \n",
    "    Only applies if both state_src and state_target are in valid_states.\n",
    "    \"\"\"\n",
    "    transition_pre = {}\n",
    "    transition_post = {}\n",
    "    pattern = r\"FROM\\s+(?P<src>\\S+)(?:\\s+STATE)?\\s+TO\\s+(?P<tgt>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        src = match.group(\"src\")\n",
    "        tgt = match.group(\"tgt\")\n",
    "        if src in valid_states and tgt in valid_states:\n",
    "            transition_pre[src] = True\n",
    "            transition_pre[tgt] = False\n",
    "            transition_post[src] = False\n",
    "            transition_post[tgt] = True\n",
    "    return transition_pre, transition_post\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    The requirement block is split into two parts based on the first occurrence of \"SHALL\" or \"SHALL NOT\":\n",
    "      - condition_part: everything before the split keyword\n",
    "      - action_part: everything after the split keyword\n",
    "    \n",
    "    The splitting keyword (captured from the regex) determines the default value for the action part:\n",
    "      - \"SHALL\" implies a default of True.\n",
    "      - \"SHALL NOT\" implies a default of False.\n",
    "    \n",
    "    From the condition_part:\n",
    "      - PRE conditions are extracted using antecedent keywords (excluding \"TO\").\n",
    "      - \"TO\" clauses are also extracted as POST conditions with a default True value.\n",
    "    \n",
    "    From the action_part:\n",
    "      - \"TO\" clauses are extracted as POST conditions with the default determined by the splitting keyword.\n",
    "    \n",
    "    Then, if a state transition pattern (FROM state_src TO state_target) is detected,\n",
    "    the conditions are updated such that:\n",
    "      - In PRE: source state becomes true and target state becomes false.\n",
    "      - In POST: source state becomes false and target state becomes true.\n",
    "    \n",
    "    Testobjects are determined by matching tokens from Variables, Components, and Objects anywhere in the block.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract valid states from the specification.\n",
    "    valid_states = set(extract_list(spec_text, \"States\"))\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    # Split using \"SHALL\" or \"SHALL NOT\" (capturing which one is used).\n",
    "    split_re = r\"\\b(SHALL(?:\\s+NOT)?)\\b\"\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        parts = re.split(split_re, block_text, maxsplit=1, flags=re.IGNORECASE)\n",
    "        if len(parts) == 3:\n",
    "            condition_part = parts[0]\n",
    "            splitting_keyword = parts[1]\n",
    "            action_part = parts[2]\n",
    "        else:\n",
    "            condition_part = block_text\n",
    "            splitting_keyword = \"SHALL\"  # default if not found\n",
    "            action_part = \"\"\n",
    "        \n",
    "        # Determine default value for the action part based on the splitting keyword.\n",
    "        action_default = False if \"NOT\" in splitting_keyword.upper() else True\n",
    "        \n",
    "        # Extract PRE from condition part (using antecedent keywords excluding \"TO\").\n",
    "        pre_conditions = extract_pre_conditions(condition_part, token_set)\n",
    "        # Extract POST conditions:\n",
    "        # From condition part: any \"TO\" clauses get default True.\n",
    "        post_conditions_condition = extract_post_conditions(condition_part, token_set, True)\n",
    "        # From action part: default as determined by the splitting keyword.\n",
    "        post_conditions_action = extract_post_conditions(action_part, token_set, action_default)\n",
    "        \n",
    "        # Combine POST conditions; if the same key appears, action part takes precedence.\n",
    "        post_conditions = {**post_conditions_condition, **post_conditions_action}\n",
    "        \n",
    "        # Filter conditions to only include states present in valid_states.\n",
    "        pre_conditions = filter_conditions_by_states(pre_conditions, valid_states)\n",
    "        post_conditions = filter_conditions_by_states(post_conditions, valid_states)\n",
    "        \n",
    "        # Apply state transition adjustments.\n",
    "        # If a \"FROM ... TO ...\" transition is found, override the values.\n",
    "        transition_pre, transition_post = extract_transition_conditions(block_text, valid_states)\n",
    "        for state, value in transition_pre.items():\n",
    "            pre_conditions[state] = value\n",
    "        for state, value in transition_post.items():\n",
    "            post_conditions[state] = value\n",
    "        \n",
    "        # Determine Testobjects by scanning the entire block for tokens in token_set.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        # Transform the flat condition dictionaries to nested ones.\n",
    "        pre_nested = transform_conditions(pre_conditions)\n",
    "        post_nested = transform_conditions(post_conditions)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_nested,\n",
    "            \"POST\": post_nested\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = \"berlin_heart.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle issue with WHILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'D:\\FOKUS\\LESS\\src\\LESS_Req_Generation\\less_testgeneration\\tests\\berlin_heart_test_with_grammar.ess' not found.\n",
      "[\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen1\",\n",
      "    \"Requirement\": \"Req_gen1\",\n",
      "    \"Testobjects\": [\n",
      "      \"systolic_pressure\",\n",
      "      \"user\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen3\",\n",
      "    \"Requirement\": \"Req_gen3\",\n",
      "    \"Testobjects\": [\n",
      "      \"systolic_pressure\",\n",
      "      \"user\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen4\",\n",
      "    \"Requirement\": \"Req_gen4\",\n",
      "    \"Testobjects\": [\n",
      "      \"systolic_pressure\",\n",
      "      \"user\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen5\",\n",
      "    \"Requirement\": \"Req_gen5\",\n",
      "    \"Testobjects\": [\n",
      "      \"compact_drive_first_switch\",\n",
      "      \"system\",\n",
      "      \"default_values_for_pressure_parameters\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"compact_drive_first_switch\": {\n",
      "        \"auto_mode\": true\n",
      "      },\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen6\",\n",
      "    \"Requirement\": \"Req_gen6\",\n",
      "    \"Testobjects\": [\n",
      "      \"last_values_manual_mode\",\n",
      "      \"compact_drive\",\n",
      "      \"system\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen7\",\n",
      "    \"Requirement\": \"Req_gen7\",\n",
      "    \"Testobjects\": [\n",
      "      \"description\",\n",
      "      \"clinical_ui\"\n",
      "    ],\n",
      "    \"PRE\": {},\n",
      "    \"POST\": {}\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen8\",\n",
      "    \"Requirement\": \"Req_gen8\",\n",
      "    \"Testobjects\": [\n",
      "      \"clinical_ui\",\n",
      "      \"user\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"Reference\": \"test-Req_gen9\",\n",
      "    \"Requirement\": \"Req_gen9\",\n",
      "    \"Testobjects\": [\n",
      "      \"clinical_ui\",\n",
      "      \"user\"\n",
      "    ],\n",
      "    \"PRE\": {\n",
      "      \"auto_mode\": true,\n",
      "      \"manual_mode\": false\n",
      "    },\n",
      "    \"POST\": {\n",
      "      \"manual_mode\": true,\n",
      "      \"auto_mode\": false\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_list(spec_text, key):\n",
    "    \"\"\"\n",
    "    Extracts a list of items for a given key (e.g., 'Variables', 'Components', 'Objects', 'States')\n",
    "    from the specification document.\n",
    "    \"\"\"\n",
    "    pattern = key + r\":\\s*\\[([^\\]]+)\\]\"\n",
    "    match = re.search(pattern, spec_text, re.DOTALL)\n",
    "    items = []\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        tokens = re.split(r\",\\s*\", content)\n",
    "        for token in tokens:\n",
    "            token = token.strip()\n",
    "            # For entries like \"user:{stateSpaces: [authorizable]}\", take the part before the colon.\n",
    "            token = token.split(\":\", 1)[0]\n",
    "            if token:\n",
    "                items.append(token)\n",
    "    return items\n",
    "\n",
    "def extract_requirements(spec_text):\n",
    "    \"\"\"\n",
    "    Extracts requirement blocks from the specification document.\n",
    "    Each block is expected to have a \"Requirement:\" line and a body enclosed in curly braces.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (requirement_id, block_text).\n",
    "    \"\"\"\n",
    "    pattern = r\"Requirement:\\s*(\\S+).*?\\{(.*?)\\}\"\n",
    "    requirements = re.findall(pattern, spec_text, re.DOTALL)\n",
    "    return requirements\n",
    "\n",
    "def extract_pre_conditions(text, token_set):\n",
    "    \"\"\"\n",
    "    Extracts antecedent (PRE) conditions from the given text.\n",
    "    \n",
    "    It uses two patterns:\n",
    "      - Pattern A (with component): matches when an antecedent keyword is preceded by a token (the component).\n",
    "      - Pattern B (without component): matches when the text starts with an antecedent keyword.\n",
    "      \n",
    "    In Pattern A, if a negation (NOT) is present, the value is False; otherwise True.\n",
    "    In Pattern B, the token immediately following the keyword is taken as the state.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A flat dictionary with keys like \"component:state\" (if a component was captured)\n",
    "              or just \"state\" (if not), and boolean values.\n",
    "    \"\"\"\n",
    "    conditions = {}\n",
    "    # Pattern A: with component (expects IF or AND before)\n",
    "    pattern_with_component = r\"(?:IF|AND)\\s+(?P<negation>NOT\\s+)?(?P<component>\\S+)\\s+(?P<keyword>FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE)))\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern_with_component, text, re.IGNORECASE):\n",
    "        negation = match.group(\"negation\") is not None\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        key = f\"{component}:{state}\"\n",
    "        conditions[key] = not negation\n",
    "    # Pattern B: without component (text starts with one of the keywords)\n",
    "    pattern_without_component = r\"\\b(?P<keyword>FROM|WHILE|IN CASE OF|DURING|IN(?!\\s+(?:AS SOON AS|TO|BEFORE)))\\s+(?P<state>\\S+)(?:\\s+IS\\s+\\S+)?(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern_without_component, text, re.IGNORECASE):\n",
    "        # To avoid duplicate matches from Pattern A, only add if not already captured in any key containing a colon.\n",
    "        state = match.group(\"state\")\n",
    "        key = state\n",
    "        conditions.setdefault(key, True)\n",
    "    return conditions\n",
    "\n",
    "def extract_post_conditions(text, token_set, default_value):\n",
    "    \"\"\"\n",
    "    Extracts consequence (POST) conditions from the given text by scanning for \"TO\" clauses.\n",
    "    \n",
    "    The pattern optionally captures a component immediately preceding \"TO\". If a valid component is captured\n",
    "    (i.e. it exists in token_set), the key becomes \"component:state\"; otherwise, the key is just \"state\".\n",
    "    \n",
    "    The boolean value for each occurrence is set to default_value.\n",
    "    \"\"\"\n",
    "    post_conditions = {}\n",
    "    pattern = r\"(?:(?P<component>\\S+)\\s+)?TO\\s+(?P<state>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        component = match.group(\"component\")\n",
    "        state = match.group(\"state\")\n",
    "        if component is not None and component in token_set:\n",
    "            key = f\"{component}:{state}\"\n",
    "        else:\n",
    "            key = state\n",
    "        post_conditions[key] = default_value\n",
    "    return post_conditions\n",
    "\n",
    "def transform_conditions(flat_conditions):\n",
    "    \"\"\"\n",
    "    Transforms a flat dictionary of conditions with keys like \"component:state\" \n",
    "    into a nested dictionary where the outer keys are component names and the inner keys are states.\n",
    "    \n",
    "    For example, {\"compact_drive:failed\": true, \"clinical_ui:is_running\": true} becomes:\n",
    "      {\n",
    "        \"compact_drive\": { \"failed\": true },\n",
    "        \"clinical_ui\": { \"is_running\": true }\n",
    "      }\n",
    "    \"\"\"\n",
    "    nested = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "            if comp in nested:\n",
    "                nested[comp][state] = value\n",
    "            else:\n",
    "                nested[comp] = { state: value }\n",
    "        else:\n",
    "            nested[key] = value\n",
    "    return nested\n",
    "\n",
    "def filter_conditions_by_states(flat_conditions, valid_states):\n",
    "    \"\"\"\n",
    "    Filters out any condition from the flat dictionary if its state is not in the valid_states set.\n",
    "    \n",
    "    For keys in the format \"component:state\", state is the substring after the colon.\n",
    "    For keys without a colon, the key itself is the state.\n",
    "    \"\"\"\n",
    "    filtered = {}\n",
    "    for key, value in flat_conditions.items():\n",
    "        if \":\" in key:\n",
    "            comp, state = key.split(\":\", 1)\n",
    "        else:\n",
    "            state = key\n",
    "        if state in valid_states:\n",
    "            filtered[key] = value\n",
    "    return filtered\n",
    "\n",
    "def extract_transition_conditions(text, valid_states):\n",
    "    \"\"\"\n",
    "    Extracts state transition conditions from text for patterns like:\n",
    "      FROM state_src TO state_target\n",
    "      \n",
    "    Returns two flat dictionaries:\n",
    "      - transition_pre: { state_src: True, state_target: False }\n",
    "      - transition_post: { state_src: False, state_target: True }\n",
    "    \n",
    "    Only applies if both state_src and state_target are in valid_states.\n",
    "    \"\"\"\n",
    "    transition_pre = {}\n",
    "    transition_post = {}\n",
    "    pattern = r\"FROM\\s+(?P<src>\\S+)(?:\\s+STATE)?\\s+TO\\s+(?P<tgt>\\S+)(?:\\s+STATE)?\"\n",
    "    for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "        src = match.group(\"src\")\n",
    "        tgt = match.group(\"tgt\")\n",
    "        if src in valid_states and tgt in valid_states:\n",
    "            transition_pre[src] = True\n",
    "            transition_pre[tgt] = False\n",
    "            transition_post[src] = False\n",
    "            transition_post[tgt] = True\n",
    "    return transition_pre, transition_post\n",
    "\n",
    "def generate_test_cases(spec_text):\n",
    "    \"\"\"\n",
    "    Generates test cases by extracting each requirement and identifying the Testobjects, PRE, and POST conditions.\n",
    "    \n",
    "    The requirement block is split into two parts based on the first occurrence of \"SHALL\" or \"SHALL NOT\":\n",
    "      - condition_part: everything before the split keyword\n",
    "      - action_part: everything after the split keyword\n",
    "    \n",
    "    The splitting keyword (captured from the regex) determines the default value for the action part:\n",
    "      - \"SHALL\" implies a default of True.\n",
    "      - \"SHALL NOT\" implies a default of False.\n",
    "    \n",
    "    From the condition_part:\n",
    "      - PRE conditions are extracted using antecedent keywords (including those that appear at the start).\n",
    "      - \"TO\" clauses are also extracted as POST conditions with a default True value.\n",
    "    \n",
    "    From the action_part:\n",
    "      - \"TO\" clauses are extracted as POST conditions with the default determined by the splitting keyword.\n",
    "    \n",
    "    Then, if a state transition pattern (FROM state_src TO state_target) is detected,\n",
    "    the conditions are updated such that:\n",
    "      - In PRE: source state becomes true and target state becomes false.\n",
    "      - In POST: source state becomes false and target state becomes true.\n",
    "    \n",
    "    Testobjects are determined by matching tokens from Variables, Components, and Objects anywhere in the block.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of test case dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract tokens from the spec.\n",
    "    variables = extract_list(spec_text, \"Variables\")\n",
    "    components = extract_list(spec_text, \"Components\")\n",
    "    objects = extract_list(spec_text, \"Objects\")\n",
    "    token_set = set(variables + components + objects)\n",
    "    \n",
    "    # Extract valid states from the specification.\n",
    "    valid_states = set(extract_list(spec_text, \"States\"))\n",
    "    \n",
    "    # Extract requirement blocks.\n",
    "    requirement_blocks = extract_requirements(spec_text)\n",
    "    test_cases = []\n",
    "    \n",
    "    # Split using \"SHALL\" or \"SHALL NOT\" (capturing which one is used).\n",
    "    split_re = r\"\\b(SHALL(?:\\s+NOT)?)\\b\"\n",
    "    \n",
    "    for req_id, block_text in requirement_blocks:\n",
    "        parts = re.split(split_re, block_text, maxsplit=1, flags=re.IGNORECASE)\n",
    "        if len(parts) == 3:\n",
    "            condition_part = parts[0]\n",
    "            splitting_keyword = parts[1]\n",
    "            action_part = parts[2]\n",
    "        else:\n",
    "            condition_part = block_text\n",
    "            splitting_keyword = \"SHALL\"  # default if not found\n",
    "            action_part = \"\"\n",
    "        \n",
    "        # Determine default value for the action part based on the splitting keyword.\n",
    "        action_default = False if \"NOT\" in splitting_keyword.upper() else True\n",
    "        \n",
    "        # Extract PRE from condition part (using our updated extraction that handles both patterns).\n",
    "        pre_conditions = extract_pre_conditions(condition_part, token_set)\n",
    "        # Extract POST conditions:\n",
    "        # From condition part: any \"TO\" clauses get default True.\n",
    "        # This handles cases where the conditional has both ante\n",
    "        post_conditions_condition = extract_post_conditions(condition_part, token_set, True)\n",
    "        # From action part: default as determined by the splitting keyword.\n",
    "        post_conditions_action = extract_post_conditions(action_part, token_set, action_default)\n",
    "        \n",
    "        # Combine POST conditions; if the same key appears, action part takes precedence.\n",
    "        post_conditions = {**post_conditions_condition, **post_conditions_action}\n",
    "        \n",
    "        # Filter conditions to only include states present in valid_states.\n",
    "        pre_conditions = filter_conditions_by_states(pre_conditions, valid_states)\n",
    "        post_conditions = filter_conditions_by_states(post_conditions, valid_states)\n",
    "        \n",
    "        # Apply state transition adjustments.\n",
    "        transition_pre, transition_post = extract_transition_conditions(block_text, valid_states)\n",
    "        for state, value in transition_pre.items():\n",
    "            pre_conditions[state] = value\n",
    "        for state, value in transition_post.items():\n",
    "            post_conditions[state] = value\n",
    "        \n",
    "        # Determine Testobjects by scanning the entire block for tokens in token_set.\n",
    "        found_tokens = set()\n",
    "        for token in token_set:\n",
    "            if re.search(r'\\b' + re.escape(token) + r'\\b', block_text):\n",
    "                found_tokens.add(token)\n",
    "        \n",
    "        # Transform the flat condition dictionaries to nested ones.\n",
    "        pre_nested = transform_conditions(pre_conditions)\n",
    "        post_nested = transform_conditions(post_conditions)\n",
    "        \n",
    "        test_case = {\n",
    "            \"Reference\": f\"test-{req_id}\",\n",
    "            \"Requirement\": req_id,\n",
    "            \"Testobjects\": list(found_tokens),\n",
    "            \"PRE\": pre_nested,\n",
    "            \"POST\": post_nested\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spec_file = r\"D:\\FOKUS\\LESS\\src\\LESS_Req_Generation\\less_testgeneration\\test_generation\\tests\\berlin_heart_test_with_grammar.ess\"  # Update with the path to your specification document.\n",
    "    try:\n",
    "        with open(spec_file, \"r\") as f:\n",
    "            spec_text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{spec_file}' not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    test_cases = generate_test_cases(spec_text)\n",
    "    print(json.dumps(test_cases, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
