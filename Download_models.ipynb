{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8571877",
   "metadata": {},
   "source": [
    "#### LLAMA 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dca8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "access_token = \"enter_token_here\"  # Replace with your actual access token\n",
    "login(access_token) # Login to Hugging Face Hub\n",
    "\n",
    "target_dir = r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\src\\LESS_Req_Generation\\less_testgeneration\\model_repository\\llama4\"\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"bartowski/meta-llama_Llama-4-Scout-17B-16E-Instruct-old-GGUF\",\n",
    "    allow_patterns=[\"meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M/*\"],\n",
    "    local_dir=target_dir,\n",
    "    local_dir_use_symlinks=False,\n",
    "    resume_download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41250c",
   "metadata": {},
   "source": [
    "#### LLAMA 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affdda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub import login\n",
    "# Model repo on Hugging Face\n",
    "model_id = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "access_token = \"enter_token_here\"\n",
    "login(access_token) # Login to Hugging Face Hub\n",
    "target_dir = r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\src\\LESS_Req_Generation\\less_testgeneration\\model_repository\\llama3_1\"\n",
    "# Download the entire model snapshot to the local directory\n",
    "snapshot_download(\n",
    "    repo_id=model_id,\n",
    "    local_dir=target_dir,   # change if you want a different folder\n",
    "    revision=\"main\",            # branch or tag (optional)\n",
    "    resume_download=True,       # resumes if interrupted\n",
    "    token=True                  # uses your HF token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5358a",
   "metadata": {},
   "source": [
    "3.1 quantized gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Model repo on Hugging Face\n",
    "model_id = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "access_token = \"enter_token_here\"\n",
    "login(access_token) # Login to Hugging Face Hub\n",
    "target_dir = r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\src\\LESS_Req_Generation\\less_testgeneration\\model_repository\\llama3_1\"\n",
    "local_file = hf_hub_download(\n",
    "    repo_id=\"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "    filename=\"Meta-Llama-3.1-8B-Instruct-Q6_K.gguf\",\n",
    "    local_dir=\"models\",\n",
    "    resume_download=True,\n",
    "    token=True  # uses your HF auth token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5b7e1",
   "metadata": {},
   "source": [
    "#### Check llama cpp uses cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_cpp\n",
    "print(\"llama_cpp version:\", llama_cpp.__version__)\n",
    "print(\"llama_cpp module location:\", llama_cpp.__file__)\n",
    "from llama_cpp import Llama\n",
    "llm = Llama(model_path=\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\src\\LESS_Req_Generation\\less_testgeneration\\model_repository\\llama4\\meta-llama_Llama-4-Scout-17B-16E-Instruct-Q4_K_M-00001-of-00002.gguf\", n_gpu_layers=-1, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_enabled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
