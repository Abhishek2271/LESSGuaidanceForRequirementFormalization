{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grammar 'D:\\FOKUS\\LESS_2\\_LESS_OLD\\grammar\\less.tx' is valid.\n",
      "[<Variable:plausibility_checks>, <Variable:faults>, <Variable:unintended_acceleration>, <Variable:errors>, <Variable:high_driving_torque>]\n",
      "The text file 'D:\\FOKUS\\LESS_2\\_LESS_OLD\\EGAS_all\\Combined\\EGAS_ALL_NLP_LESS_Pair_CORRECT.ess' is valid according to the grammar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Model:Egas>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from textx import metamodel_from_file, TextXError\n",
    "\n",
    "def validate_textx_grammar_and_text(grammar_file, text_file):\n",
    "    \"\"\"\n",
    "    Validates a text file against the given textX grammar.\n",
    "\n",
    "    param:\n",
    "        grammar_file: Path to the textX grammar file (.tx).\n",
    "        text_file: input file to valdate.\n",
    "    \"\"\"\n",
    "    \n",
    "    #check grammar file if valid (for now this is always valid)\n",
    "    metamodel = metamodel_from_file(grammar_file)\n",
    "    print(f\"The grammar '{grammar_file}' is valid.\")\n",
    "\n",
    "    try:\n",
    "        #use the meta-model to see if the input file builds a valid model\n",
    "        with open(text_file, 'r') as f:\n",
    "            text_content = f.read()\n",
    "        model = metamodel.model_from_str(text_content)\n",
    "        var = model.variables\n",
    "        print(var)\n",
    "        print(f\"The text file '{text_file}' is valid according to the grammar.\")\n",
    "        requirements = getattr(model, 'requirements', None)\n",
    "       # for req in requirements:\n",
    "       #     print((req.req.specification.object))\n",
    "            #print((req.req.specification.object[0].object.ob))\n",
    "            #print((req.req.specification.object[1].object.ob))\n",
    "        \n",
    "        return model\n",
    "    except TextXError as e:\n",
    "        print(f\"Error validating text against grammar: {e}\")\n",
    "\n",
    "#base file\n",
    "grammar_path = r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\grammar\\less.tx\"\n",
    "#updated grammar file with generate requirements\n",
    "#text_path= r\"D:\\FOKUS\\LESS\\grammar\\specs.txt\"\n",
    "text_path= r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\src\\LESS_Req_Generation\\less_testgeneration\\Results\\berlin_heart.ess\"\n",
    "#text_path= r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\EGAS_all\\Combined\\EGAS_ALL_NLP_LESS_Pair_CORRECT.ess\"\n",
    "validate_textx_grammar_and_text(grammar_path, text_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Literal validation with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "def normalize_text(text):\n",
    "    return ''.join(text.split())\n",
    "\n",
    "def calculate_literal_similarity(file1_path, file2_path):\n",
    "    text1 = normalize_text(read_file(file1_path))\n",
    "    text2 = normalize_text(read_file(file2_path))\n",
    "\n",
    "    matching_chars = sum(1 for a, b in zip(text1, text2) if a == b)\n",
    "    total_chars = max(len(text1), len(text2))\n",
    "\n",
    "    similarity = matching_chars / total_chars if total_chars > 0 else 1.0\n",
    "    return similarity\n",
    "\n",
    "file1 = \"D:\\FOKUS\\LESS\\less_req_mapping_target_TARGET.txt\"  # Path to the first text file\n",
    "file2 = \"D:\\FOKUS\\LESS\\less_req_mapping_target_GENERATED_GPT.json\"  # Path to the second text file\n",
    "\n",
    "similarity_score = calculate_literal_similarity(file1, file2)\n",
    "print(f\"Literal similarity between the two files: {similarity_score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DYNAMIC VALIDATION OF GENERATED LESS CONTENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Define file paths\n",
    "#json file that is generated by the llm, this file will be validated\n",
    "json_file = r\"D:\\FOKUS\\LESS_2\\SE_26\\Results\\requirement_generation\\indirect_prompts\\3_deepseekV3\\prompt14\\run2__TAKEN\\prompt_14_indirect_deepseek_corrected.json\"\n",
    "\n",
    "#the less grammar file, this will be used for validation\n",
    "tx_grammar_file = r\"D:\\FOKUS\\LESS\\grammar\\less.tx\"\n",
    "\n",
    "#dynamic grammar file that will be updated in each iteration. the less requirement in this file will be replaced by the LESS attribute content from the llm generated file\n",
    "dynamic_grammar = r\"D:\\FOKUS\\LESS_2\\_LESS_OLD\\src\\LESS_Req_Generation\\less_testgeneration\\grammar\\EGas\\dynamic_grammar.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Errors:\n",
      "Line14, LESS: IF unintended acceleration THEN THE Engine_Control_Unit SHALL SWITCH TO safe_state, Error: None:108:19: Unknown object \"acceleration\" of class \"ObjectAttribute\"\n",
      "Line21, LESS: THE Power_Switch SHALL DETECT spoofing OF THE Lamp_switch_on_request BY verifying THE MAC, Error: None:108:44: Unknown object \"OF\" of class \"OBJECT\"\n",
      "Line22, LESS: THE Power_Switch SHALL drop ANY Lamp_switch_on_request THAT ARE detected AS spoofed, Error: None:108:66: Unknown object \"RE\" of class \"OBJECT\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from textx import metamodel_from_file, TextXError, TextXSyntaxError\n",
    "\n",
    "# Load LLM generated JSON file\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Replace the line in the dynamic.txt file\n",
    "def replace_line_in_tx(less_line, tx_file_path):\n",
    "    with open(tx_file_path, 'r') as f:\n",
    "        tx_content = f.readlines()\n",
    "\n",
    "    updated_lines = []\n",
    "    inside_requirements = False\n",
    "    skip_block = False\n",
    "    for line in tx_content:\n",
    "        if \"RequirementClassification: SecurityFunctional\" in line:\n",
    "            inside_requirements = True\n",
    "            updated_lines.append(line)\n",
    "        elif inside_requirements and \"{\" in line:\n",
    "            # replace the less requirement in the dynamic_grammar file with the less line that is read\n",
    "            updated_lines.append(f\"\\t\\t\\t{{\\n\\t\\t\\t\\t{less_line}\\n\\t\\t\\t}}\\n\")\n",
    "            skip_block = True  # Skip until the closing '}'\n",
    "        elif inside_requirements and \"}\" in line and skip_block:\n",
    "            skip_block = False\n",
    "            inside_requirements = False\n",
    "        elif not skip_block:\n",
    "            updated_lines.append(line)\n",
    "\n",
    "    return ''.join(updated_lines)\n",
    "\n",
    "# Validate the txt file ussing the tx grammar that specified less\n",
    "def validate_tx(txt_content, tx_grammar_file):\n",
    "    try:\n",
    "        mm = metamodel_from_file(tx_grammar_file)\n",
    "        a = mm.model_from_str(txt_content)\n",
    "       # pprint(vars(a.requirements[0].req.specification))\n",
    "       # print(\"____\")\n",
    "       #pprint(vars(a.requirements[0].req.specification.conditionals))\n",
    "       # print((a.requirements[0].req.specification.conditionals.condition[0].lit))\n",
    "       #pprint(vars(a))\n",
    "        return None  # No errors\n",
    "    except TextXError as e:\n",
    "        return str(e)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    validation_errors = []\n",
    "\n",
    "    # Load JSON data\n",
    "    json_data = load_json(json_file)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    1. Read individual lines from the LLM generated json\n",
    "    2. For each line create a specification document (in this case the dynamic_grammar file is updated everytime)\n",
    "    3. Validate the dynamic_grammar file (against LESS grammar)\n",
    "    4. When errors occur, log them\n",
    "    \n",
    "    This whole process is required because it seems that there is no way to allow textX grammar to move past errors. It will stop at any error.\n",
    "    \n",
    "    The program therefore checks which LESS specifications were correclty generated and which were incorrect.\n",
    "    \n",
    "    This is then the \"Validation\" of LESS grammar to judge performance of the LLM\n",
    "    \"\"\"\n",
    "    line_count = 0\n",
    "    for item in json_data:\n",
    "        line_count = line_count + 1\n",
    "        less_line = item['LESS']\n",
    "\n",
    "        updated_content = replace_line_in_tx(less_line, dynamic_grammar)\n",
    "\n",
    "        # Validate updated tx file\n",
    "        #print(updated_content)\n",
    "        error = validate_tx(updated_content, tx_grammar_file)\n",
    "        if error:\n",
    "            validation_errors.append({\"Line_number\": line_count , \"LESS\": less_line, \"Error\": error})\n",
    "\n",
    "\n",
    "    # Print validation errors\n",
    "    if validation_errors:\n",
    "        print(\"Validation Errors:\")\n",
    "        for error in validation_errors:\n",
    "            print(f\"Line{error['Line_number']}, LESS: {error['LESS']}, Error: {error['Error']}\")\n",
    "    else:\n",
    "        print(\"All LESS lines processed and validated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_enabled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
